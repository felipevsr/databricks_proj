{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e131447-c495-44ec-ba24-2f9c3c5da782",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![IBGE LOGO](https://www.infoescola.com/wp-content/uploads/2008/02/IBGE.png)\n",
    "\n",
    "\n",
    "\n",
    "## API IBGE Noticias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af9098e6-e5f4-4de8-b5ec-b643079b2c97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "import pytz\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da8ef31c-8546-411b-a7b5-ffc802cd755f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'202410'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time_file = datetime.now(pytz.timezone('America/Sao_Paulo')).strftime('%Y%m%d_%H%M%S')\n",
    "# time_file[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3cbf379-47ca-4e34-b0d4-26784726a705",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/raw_3/202410/</td><td>202410/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/raw_3/202410/",
         "202410/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls('dbfs:/mnt/raw_3/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97c196a8-33a5-4bc8-80d3-ac04317f1922",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['202410']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_date = [lst_date.name.replace('/','') for lst_date in dbutils.fs.ls('dbfs:/mnt/raw_3/')]\n",
    "lst_date.sort()\n",
    "lst_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f7b7990-a355-4cf5-9589-ddfd779c5115",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1003844304658914>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m valor_maximo_raw \u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mint\u001B[39m(i\u001B[38;5;241m.\u001B[39mname\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) ) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mls(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdbfs:/mnt/raw_3/\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n",
       "\u001B[1;32m      2\u001B[0m valor_maximo_raw\u001B[38;5;241m.\u001B[39msort()\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# valor_maximo_raw = valor_maximo_raw[-1]\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:380\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    378\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    379\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 380\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
       "\n",
       "\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o410.ls.\n",
       ": java.io.FileNotFoundException: /mnt/raw_3\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:122)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.listStatus(DatabricksFileSystemV1.scala:179)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:164)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.lsWithLimit(DBUtilsCore.scala:295)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$4(DBUtilsCore.scala:264)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withFsSafetyCheck(DBUtilsCore.scala:151)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$3(DBUtilsCore.scala:264)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.checkPermission(DBUtilsCore.scala:146)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.lsImpl(DBUtilsCore.scala:263)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$ls$1(DBUtilsCore.scala:236)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala:236)\n",
       "\tat sun.reflect.GeneratedMethodAccessor760.invoke(Unknown Source)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ExecutionError",
        "evalue": "An error occurred while calling o410.ls.\n: java.io.FileNotFoundException: /mnt/raw_3\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:122)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.listStatus(DatabricksFileSystemV1.scala:179)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:164)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.lsWithLimit(DBUtilsCore.scala:295)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$4(DBUtilsCore.scala:264)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withFsSafetyCheck(DBUtilsCore.scala:151)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$3(DBUtilsCore.scala:264)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.checkPermission(DBUtilsCore.scala:146)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.lsImpl(DBUtilsCore.scala:263)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$ls$1(DBUtilsCore.scala:236)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala:236)\n\tat sun.reflect.GeneratedMethodAccessor760.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ExecutionError</span>: An error occurred while calling o410.ls.\n: java.io.FileNotFoundException: /mnt/raw_3\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:122)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.listStatus(DatabricksFileSystemV1.scala:179)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:164)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.lsWithLimit(DBUtilsCore.scala:295)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$4(DBUtilsCore.scala:264)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withFsSafetyCheck(DBUtilsCore.scala:151)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$3(DBUtilsCore.scala:264)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.checkPermission(DBUtilsCore.scala:146)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.lsImpl(DBUtilsCore.scala:263)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$ls$1(DBUtilsCore.scala:236)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala:236)\n\tat sun.reflect.GeneratedMethodAccessor760.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)",
        "File \u001B[0;32m<command-1003844304658914>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m valor_maximo_raw \u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mint\u001B[39m(i\u001B[38;5;241m.\u001B[39mname\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) ) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mls(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdbfs:/mnt/raw_3/\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m      2\u001B[0m valor_maximo_raw\u001B[38;5;241m.\u001B[39msort()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# valor_maximo_raw = valor_maximo_raw[-1]\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:380\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    378\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    379\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 380\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
        "\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o410.ls.\n: java.io.FileNotFoundException: /mnt/raw_3\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:122)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.listStatus(DatabricksFileSystemV1.scala:179)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:164)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.lsWithLimit(DBUtilsCore.scala:295)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$4(DBUtilsCore.scala:264)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withFsSafetyCheck(DBUtilsCore.scala:151)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$lsImpl$3(DBUtilsCore.scala:264)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.checkPermission(DBUtilsCore.scala:146)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.lsImpl(DBUtilsCore.scala:263)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.$anonfun$ls$1(DBUtilsCore.scala:236)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.ls(DBUtilsCore.scala:236)\n\tat sun.reflect.GeneratedMethodAccessor760.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "      valor_maximo_raw =[int(i.name.split('_')[-1].replace(\"/\",\"\") ) for i in dbutils.fs.ls(f'dbfs:/mnt/raw_3/')]\n",
    "      valor_maximo_raw.sort()\n",
    "      valor_maximo_raw = valor_maximo_raw[-1]\n",
    "      valor_maximo_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee12a4c6-b53d-4982-a44d-7f2e038c1198",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_folder_date = [lst_date.name.replace('/','') for lst_date in dbutils.fs.ls('dbfs:/mnt/raw_3/')]\n",
    "lst_folder_date.sort()\n",
    "# lst_folder_date\n",
    "\n",
    "# valor_maximo_raw =[int(i.name.split('_')[-1].replace(\"/\",\"\") ) for i in dbutils.fs.ls(f'dbfs:/mnt/raw_3/{lst_folder_date[-1]}/')]\n",
    "# valor_maximo_raw.sort()\n",
    "# valor_maximo_raw = valor_maximo_raw[-1]\n",
    "# valor_maximo_raw\n",
    "# lst_folder_date = [lst_date.name.replace('/','') for lst_date in dbutils.fs.ls(f'dbfs:/mnt/raw_3/')]\n",
    "# lst_folder_date.sort()\n",
    "# valor_maximo_raw =[int(i.name.split(\"_\")[3]) for i in dbutils.fs.ls(f'dbfs:/mnt/raw_3/{lst_folder_date[-1]}/')]\n",
    "# valor_maximo_raw.sort()\n",
    "# valor_maximo_raw = valor_maximo_raw[-1]\n",
    "# valor_maximo_raw\n",
    "\n",
    "lst_folder_date = [lst_date.name.replace('/','') for lst_date in dbutils.fs.ls(f'{self.raw_directory}')]\n",
    "lst_folder_date.sort()\n",
    "valor_maximo_raw =[int(i.name.split(\"_\")[3]) for i in dbutils.fs.ls(f'{self.raw_directory}{lst_folder_date[-1]}/')]\n",
    "valor_maximo_raw.sort()\n",
    "valor_maximo_raw = valor_maximo_raw[-1]\n",
    "valor_maximo_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "749798a0-35cf-4c2a-8107-3329bfdc6cad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [i.name.replace(\"/\",\"\") for i in dbutils.fs.ls(f'dbfs:/mnt/raw_3/')]\n",
    "\n",
    "## Verifica a pasta data mais recente ###\n",
    "lst_folder_date = [lst_date.name.replace('/','') for lst_date in dbutils.fs.ls('dbfs:/mnt/raw_3/')]\n",
    "lst_folder_date.sort()\n",
    "### Verifica a pasta de ingestao da API de dados mais recente  ###\n",
    "try:\n",
    "  contagem =[int(i.name.split(\"_\")[3]) for i in dbutils.fs.ls(f'dbfs:/mnt/raw_3/{lst_folder_date[-1]}/')]\n",
    "  # contagem =[int(i.name.split(\"_\")[3]) for i in dbutils.fs.ls(f'dbfs:/mnt/raw_3/202411/')]\n",
    "  contagem.sort()\n",
    "  contagem = contagem[-1]\n",
    "  contagem\n",
    "except:\n",
    "  contagem = 1\n",
    "contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e855f3f-d653-49fa-82fe-38a009ebd720",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'202411'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_datas = ['202411','202410','202409','202311']\n",
    "lista_datas.sort()\n",
    "lista_datas[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01920bcb-a5d5-4e75-9b37-a14dcdcbf5da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1003844304658913>, line 6\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mO divisor não pode ser zero!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m a \u001B[38;5;241m/\u001B[39m b\n",
       "\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(dividir(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n",
       "\n",
       "File \u001B[0;32m<command-1003844304658913>, line 3\u001B[0m, in \u001B[0;36mdividir\u001B[0;34m(a, b)\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdividir\u001B[39m(a, b):\n",
       "\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m b \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m----> 3\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mO divisor não pode ser zero!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m a \u001B[38;5;241m/\u001B[39m b\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: O divisor não pode ser zero!"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "O divisor não pode ser zero!"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: O divisor não pode ser zero!"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-1003844304658913>, line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mO divisor não pode ser zero!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m a \u001B[38;5;241m/\u001B[39m b\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(dividir(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n",
        "File \u001B[0;32m<command-1003844304658913>, line 3\u001B[0m, in \u001B[0;36mdividir\u001B[0;34m(a, b)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdividir\u001B[39m(a, b):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m b \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m----> 3\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mO divisor não pode ser zero!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m a \u001B[38;5;241m/\u001B[39m b\n",
        "\u001B[0;31mValueError\u001B[0m: O divisor não pode ser zero!"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75c9285f-456d-47a0-9d35-e606e30247f2",
     "showTitle": true,
     "title": "Classe de ingestao"
    }
   },
   "outputs": [],
   "source": [
    "class RawLayerIngestion:\n",
    "\n",
    "  def __init__(self,url,first_page,raw_directory):\n",
    "    self.URL_API = url\n",
    "    self.first_page = first_page\n",
    "    self.raw_directory = raw_directory\n",
    "\n",
    "  def raw_ingestion(self):\n",
    "    try:\n",
    "      ## Verifica a pasta data mais recente ###\n",
    "      lst_folder_date = [lst_date.name.replace('/','') for lst_date in dbutils.fs.ls(f'{self.raw_directory}')]\n",
    "      lst_folder_date.sort()\n",
    "      ### Verifica a pasta de ingestao da API de dados mais recente  ###\n",
    "      valor_maximo_raw =[int(i.name.split(\"_\")[3]) for i in dbutils.fs.ls(f'{self.raw_directory}{lst_folder_date[-1]}/')]\n",
    "      valor_maximo_raw.sort()\n",
    "      valor_maximo_raw = valor_maximo_raw[-1]\n",
    "      ## Verificando numero total de paginas ##\n",
    "      content_json = requests.get(\"{url}?page={page}\".format(url=self.URL_API,page=self.first_page))\n",
    "      content_json = content_json.json()\n",
    "      print(\"Ultima pagina inserida na RAw ==>  \" ,valor_maximo_raw)\n",
    "      acumulo_paginas = []\n",
    "      np_acumulo = []\n",
    "      contador = valor_maximo_raw\n",
    "      if valor_maximo_raw <= content_json[\"totalPages\"]:\n",
    "\n",
    "        print(f\"Iniciando Proceeso a partit da pagina ==> {contador}\")\n",
    "        while contador <= content_json[\"totalPages\"]:\n",
    "          noticias_API = requests.get(\"{url}?page={contador}\".format(url=self.URL_API,contador=contador))\n",
    "          noticias_json = noticias_API.json()\n",
    "          acumulo_paginas.append(noticias_json[\"items\"])\n",
    "          np_acumulo.append(noticias_json['page'])\n",
    "          ##### Data e hora de ingestao na camada RAW   ####\n",
    "          time_file = datetime.now(pytz.timezone('America/Sao_Paulo')).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "          if noticias_json[\"items\"] != [] and str(noticias_json[\"page\"])[-1] == \"0\":\n",
    "\n",
    "            result_acumulo_paginas =[acumulo_paginas[i][item] for i in range(0,len(acumulo_paginas))\n",
    "                                                                for item in range(0,len(acumulo_paginas[i]))]   \n",
    "            df = spark.createDataFrame(result_acumulo_paginas).withColumn(f'PAGE',lit(f\"{np_acumulo[0]} - to - {np_acumulo[-1]} - {time_file}\"))\n",
    "            print(f\"\\t Gravando até a pagina {contador}  no diretorio dbfs {self.raw_directory}{time_file[0:6]}/\")\n",
    "            df.write.mode(\"overwrite\").json(f'{self.raw_directory}{time_file[0:6]}/ibgeapipage_{np_acumulo[0]}_to_{np_acumulo[-1]}_{time_file}')\n",
    "            acumulo_paginas = []\n",
    "            np_acumulo = []\n",
    "          elif  noticias_json[\"page\"] == content_json[\"totalPages\"]:\n",
    "            ### Ajuntando todas as paginas appendadas em uma lista unica ####\n",
    "            result_acumulo_paginas =[acumulo_paginas[i][item] for i in range(0,len(acumulo_paginas))\n",
    "                                                                    for item in range(0,len(acumulo_paginas[i]))]  \n",
    "            df = spark.createDataFrame(result_acumulo_paginas).withColumn(f'PAGE',lit(f\"{np_acumulo[0]} - to - {np_acumulo[-1]} - {time_file}\"))\n",
    "            print(f\"\\t Gravando a pagina {contador}  no diretorio dbfs {self.raw_directory}{time_file[0:6]}/\")\n",
    "            df.write.mode(\"overwrite\").json(f'{self.raw_directory}{time_file[0:6]}/ibgeapipage_{np_acumulo[0]}_to_{np_acumulo[-1]}_{time_file}')\n",
    "            acumulo_paginas = []\n",
    "            np_acumulo = []\n",
    "\n",
    "          contador = contador +1\n",
    "        print(\"Processo finalizado\")\n",
    "      else:\n",
    "        print(\"Todas as paginas da API ja foram inseridas na camada RAW\")\n",
    "\n",
    "    except:\n",
    "      try:\n",
    "        print(\"Primeira ingestão ou Nao possui arquivos na Data corrente\")\n",
    "        print(\"Buscando noticias desde a pagina ....\")\n",
    "        noticias_API = requests.get(\"{url}?page={page}\".format(url=self.URL_API,page=self.first_page))\n",
    "        noticias_json = noticias_API.json()\n",
    "        acumulo_paginas = []\n",
    "        np_acumulo = []\n",
    "\n",
    "        try:\n",
    "                ## Verifica a pasta data mais recente ###\n",
    "          lst_folder_date = [lst_date.name.replace('/','') for lst_date in dbutils.fs.ls(f'{self.raw_directory}')]\n",
    "          lst_folder_date.sort()\n",
    "          ### Verifica a pasta de ingestao da API de dados mais recente para adicionar ao contador  ###\n",
    "          contador =[int(i.name.split(\"_\")[3]) for i in dbutils.fs.ls(f'{self.raw_directory}{lst_folder_date[-1]}/')]\n",
    "          contador.sort()\n",
    "          contador = contador[-1]\n",
    "        except:\n",
    "          contador = 1\n",
    "\n",
    "        while contador <= noticias_json[\"totalPages\"]:\n",
    "          noticias_API = requests.get(\"{url}?page={contador}\".format(url=self.URL_API,contador=contador))\n",
    "          noticias_json = noticias_API.json()\n",
    "          acumulo_paginas.append(noticias_json[\"items\"])\n",
    "          np_acumulo.append(noticias_json['page'])\n",
    "          ##### Data e hora de ingestao na camada RAW   ####\n",
    "          time_file = datetime.now(pytz.timezone('America/Sao_Paulo')).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "          if noticias_json[\"items\"] != [] and str(noticias_json[\"page\"])[-1] == \"0\":\n",
    "\n",
    "            result_acumulo_paginas =[acumulo_paginas[i][item] for i in range(0,len(acumulo_paginas))\n",
    "                                                                for item in range(0,len(acumulo_paginas[i]))]   \n",
    "            \n",
    "            df = spark.createDataFrame(result_acumulo_paginas).withColumn(f'PAGE',lit(f\"{np_acumulo[0]} - to - {np_acumulo[-1]} - {time_file}\"))\n",
    "            print(f\"\\t Gravando até a pagina {contador}  no diretorio dbfs {self.raw_directory}{time_file[0:6]}/\")\n",
    "            df.write.mode(\"overwrite\").json(f'{self.raw_directory}{time_file[0:6]}/ibgeapipage_{np_acumulo[0]}_to_{np_acumulo[-1]}_{time_file}')\n",
    "            acumulo_paginas = []\n",
    "            np_acumulo = []\n",
    "          elif noticias_json[\"page\"] == noticias_json[\"totalPages\"]:\n",
    "            print(f\"Gravando todas as paginas até {contador}  no diretorio dbfs {self.raw_directory}{time_file[0:6]}/\")\n",
    "            ### Ajuntando todas as paginas appendadas em uma lista unica ####\n",
    "            result_acumulo_paginas =[acumulo_paginas[i][item] for i in range(0,len(acumulo_paginas))\n",
    "                                                                  for item in range(0,len(acumulo_paginas[i]))]  \n",
    "            \n",
    "            df = spark.createDataFrame(result_acumulo_paginas).withColumn(f'PAGE',lit(f\"{np_acumulo[0]} - to - {np_acumulo[-1]} - {time_file}\"))\n",
    "            df.write.mode(\"overwrite\").json(f'{self.raw_directory}{time_file[0:6]}/ibgeapipage_{np_acumulo[0]}_to_{np_acumulo[-1]}_{time_file}')\n",
    "            acumulo_paginas = []\n",
    "            np_acumulo = []\n",
    "          contador = contador +1\n",
    "        print(\"Processo finalizado\")\n",
    "      except Exception as e:\n",
    "        print(f\"===>>>> {e}\")\n",
    "\n",
    "  def start_run(self):\n",
    "    self.raw_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72f16fb8-4698-4447-8b94-acd513f767f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultima pagina inserida na RAw ==>   205\nIniciando Proceeso a partit da pagina ==> 205\n\t Gravando a pagina 205  no diretorio dbfs dbfs:/mnt/raw_3/202410/\nProcesso finalizado\n"
     ]
    }
   ],
   "source": [
    "ingestao_raw = RawLayerIngestion('http://servicodados.ibge.gov.br/api/v3/noticias/',1,'dbfs:/mnt/raw_3/')\n",
    "ingestao_raw.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98fa5b56-c2c0-487e-9a6e-2c0d0c925558",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_101_to_110_20241019_110833/</td><td>ibgeapipage_101_to_110_20241019_110833/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_111_to_120_20241019_110842/</td><td>ibgeapipage_111_to_120_20241019_110842/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_11_to_20_20241019_110711/</td><td>ibgeapipage_11_to_20_20241019_110711/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_121_to_130_20241019_110852/</td><td>ibgeapipage_121_to_130_20241019_110852/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_131_to_140_20241019_110901/</td><td>ibgeapipage_131_to_140_20241019_110901/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_141_to_150_20241019_110910/</td><td>ibgeapipage_141_to_150_20241019_110910/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_151_to_160_20241019_110920/</td><td>ibgeapipage_151_to_160_20241019_110920/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_161_to_170_20241019_110929/</td><td>ibgeapipage_161_to_170_20241019_110929/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_171_to_180_20241019_110938/</td><td>ibgeapipage_171_to_180_20241019_110938/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_181_to_190_20241019_110947/</td><td>ibgeapipage_181_to_190_20241019_110947/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_191_to_200_20241019_110956/</td><td>ibgeapipage_191_to_200_20241019_110956/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_1_to_10_20241019_110702/</td><td>ibgeapipage_1_to_10_20241019_110702/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_201_to_205_20241019_111001/</td><td>ibgeapipage_201_to_205_20241019_111001/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_205_to_205_20241019_111039/</td><td>ibgeapipage_205_to_205_20241019_111039/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_21_to_30_20241019_110720/</td><td>ibgeapipage_21_to_30_20241019_110720/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_31_to_40_20241019_110729/</td><td>ibgeapipage_31_to_40_20241019_110729/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_41_to_50_20241019_110739/</td><td>ibgeapipage_41_to_50_20241019_110739/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_51_to_60_20241019_110748/</td><td>ibgeapipage_51_to_60_20241019_110748/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_61_to_70_20241019_110757/</td><td>ibgeapipage_61_to_70_20241019_110757/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_71_to_80_20241019_110806/</td><td>ibgeapipage_71_to_80_20241019_110806/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_81_to_90_20241019_110815/</td><td>ibgeapipage_81_to_90_20241019_110815/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/raw_3/202410/ibgeapipage_91_to_100_20241019_110824/</td><td>ibgeapipage_91_to_100_20241019_110824/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_101_to_110_20241019_110833/",
         "ibgeapipage_101_to_110_20241019_110833/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_111_to_120_20241019_110842/",
         "ibgeapipage_111_to_120_20241019_110842/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_11_to_20_20241019_110711/",
         "ibgeapipage_11_to_20_20241019_110711/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_121_to_130_20241019_110852/",
         "ibgeapipage_121_to_130_20241019_110852/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_131_to_140_20241019_110901/",
         "ibgeapipage_131_to_140_20241019_110901/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_141_to_150_20241019_110910/",
         "ibgeapipage_141_to_150_20241019_110910/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_151_to_160_20241019_110920/",
         "ibgeapipage_151_to_160_20241019_110920/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_161_to_170_20241019_110929/",
         "ibgeapipage_161_to_170_20241019_110929/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_171_to_180_20241019_110938/",
         "ibgeapipage_171_to_180_20241019_110938/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_181_to_190_20241019_110947/",
         "ibgeapipage_181_to_190_20241019_110947/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_191_to_200_20241019_110956/",
         "ibgeapipage_191_to_200_20241019_110956/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_1_to_10_20241019_110702/",
         "ibgeapipage_1_to_10_20241019_110702/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_201_to_205_20241019_111001/",
         "ibgeapipage_201_to_205_20241019_111001/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_205_to_205_20241019_111039/",
         "ibgeapipage_205_to_205_20241019_111039/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_21_to_30_20241019_110720/",
         "ibgeapipage_21_to_30_20241019_110720/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_31_to_40_20241019_110729/",
         "ibgeapipage_31_to_40_20241019_110729/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_41_to_50_20241019_110739/",
         "ibgeapipage_41_to_50_20241019_110739/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_51_to_60_20241019_110748/",
         "ibgeapipage_51_to_60_20241019_110748/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_61_to_70_20241019_110757/",
         "ibgeapipage_61_to_70_20241019_110757/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_71_to_80_20241019_110806/",
         "ibgeapipage_71_to_80_20241019_110806/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_81_to_90_20241019_110815/",
         "ibgeapipage_81_to_90_20241019_110815/",
         0,
         0
        ],
        [
         "dbfs:/mnt/raw_3/202410/ibgeapipage_91_to_100_20241019_110824/",
         "ibgeapipage_91_to_100_20241019_110824/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls('dbfs:/mnt/raw_3/202410/'))\n",
    "\n",
    "# df2.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86bfa605-5efd-496a-a114-6792e8a32474",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df2 = spark.read.json('dbfs:/mnt/raw_3/202410/*')\n",
    "\n",
    "# df2.display()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "raw_ingestion_run_API_IBGE_Noticias",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
